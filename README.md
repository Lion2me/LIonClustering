## Lion2me의 NLP 공부 라이브러리입니다.

Jupyter notebook 환경에서 진행 후 올리므로 최적화까지 시간이 걸립니다.

## Lion2me의 NLP 공부 라이브러리입니다.

1. Clustering [ K-Means ]

K-Means 클러스터링을 구현해보았습니다.

K-Means의 경우 Distance를 계산하는 방식에 따라 효과가 달라짐을 볼 수 있습니다. 현재까지 Cosine , Euclidean , corr , jaccard 방식이 구현되었습니다. 추후에 확률분포의 차이를 구하는 KL-Divergence 를 이용해 볼 예정입니다.

논문에서는 KL-Divergence의 스케일을 잘 적용했지만, 저는 아직 부족한 점이 있어서 그 부분은 차차 넓혀보겠습니다.

```python
clus = clustering()

CV = CountVectorizer()
TV = TfidfTransformer()

CVmodel = CV.fit_transform(test)
TVmodel = TV.fit_transform(CVmodel)

clus.fit(data = TVmodel)

clus.clusters[0].get_centroid()
```


2. FastText Doc2Vec

정확한 Doc2Vec 진행 방식이 아닙니다. 여기서 문장의 벡터는 등장하는 단어 벡터의 평균으로 진행했습니다.

방식은 FastText를 통해 해당 문장의 단어 벡터들의 평균을 구한 뒤 저장합니다.

```python

# 여기서 model_path는 FastText를 통해 얻어진 모델입니다.
model = fd2v(model_path = './petitions_word_model.bin')

# fit을 통해 각 문장에 대한 벡터를 구합니다.
# 문장에 대한 벡터는 등장 단어 벡터의 평균입니다.
model.fit(petitions_text)
```

fit을 마치면 모든 문장의 벡터가 들어있기 때문에 원하는 작업을 진행 할 수 있습니다.

```python
input_= '청소년'
model.model.get_nearest_neighbors(input_)

-------------------------------

[(0.9044303894042969, '청소년및'),
 (0.8942788243293762, '청소년폭력'),
 (0.8893114328384399, '청소년용'),
 (0.8861926794052124, '청소년대상'),
 (0.8856853246688843, '청소년용과'),
 (0.8692178726196289, '청소년일'),
 (0.8685765862464905, '청소년'),
 (0.8658358454704285, '청소년증'),
 (0.8623796105384827, '청소년등'),
 (0.8612908720970154, '청소년보호')]
```

입력했던 FastText 모델은 model의 이름으로 입력되어 있으므로 사용할 수 있습니다.

```python
model.fit_knn_docs()
```

fit_knn_docs는 sklearn의 KNN을 사용했습니다.

저장 된 문장 벡터를 기반으로 knn 모델을 만듭니다. 이 과정에서 파라미터를 정할 수 있도록 변경하도록 하겠습니다.

```python
input_ = "청소년들의 범죄"
model.get_knn_docs(input_)

{'distance': array([[0.41203612, 0.42030394, 0.4212376 , 0.42178512, 0.4224677 ,
         0.42316353, 0.43128324, 0.43642706, 0.43715572, 0.43752843]],
       dtype=float32),
 'indices': array([[ 79739,  63776, 116940,  22991,  87623, 102335,  22952, 187072,
          18268, 116996]])}
```

추가적으로 단어를 기반으로 해당 단어와 유사한 단어가 등장하는 모델을 만들어 보았습니다. 데이터 전체를 탐색하며 연산하므로 시간이 매우 느립니다만, 키워드를 기반으로 탐색하는 방법으로 꽤 괜찮은 결과가 나왔습니다.

```python
model.get_similar_key_docs(input_,petitions_text)


# 첫번째 값은 max heap의 사용때문에 넣었습니다.
[(-0.53092664, 0.53092664, 223587),
 (-0.52915925, 0.52915925, 300356),
 (-0.47592646, 0.47592646, 64489),
 (-0.5158793, 0.5158793, 90852),
 (-0.4864934, 0.4864934, 364480),
 (-0.3284487, 0.3284487, 2655),
 (-0.46308434, 0.46308434, 244445),
 (-0.51326764, 0.51326764, 273069),
 (-0.45213115, 0.45213115, 299748),
 (-0.47793502, 0.47793502, 391832)]

```
